{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a1c484",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION LEARNING TASKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53c71d",
   "metadata": {},
   "source": [
    "1. Email Spam — Logistic Regression (binary)\n",
    "Task: Fit is_spam ~ features with LogisticRegression (scaled). Report accuracy, precision, recall, F1, ROC-AUC, and a confusion matrix.\n",
    "Columns: word_free, word_offer, word_click, num_links, num_caps, sender_reputation, is_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2105aee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n",
      "Precision: 0.18181818181818182\n",
      "Recall: 0.09523809523809523\n",
      "f1: 0.125\n",
      "ROC-AUC: 0.3107769423558898\n",
      "Confusion matrix: [[10  9]\n",
      " [19  2]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score,roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df=pd.read_csv('email_spam.csv')\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test,y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test,y_pred)}')\n",
    "print(f'f1: {f1_score(y_test,y_pred)}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_test,y_pred)}')\n",
    "print(f'Confusion matrix: {confusion_matrix(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1215bb",
   "metadata": {},
   "source": [
    "2. 2) Customer Churn — Logistic Regression (binary)\n",
    "Task: Fit churn ~ tenure_months + monthly_charges + support_tickets + is_premium + avg_usage_hours (scaled). Report metrics as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ead4eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.6521739130434783\n",
      "Recall: 0.6521739130434783\n",
      "f1: 0.6521739130434783\n",
      "ROC-AUC: 0.5907928388746804\n",
      "Confusion matrix: [[ 9  8]\n",
      " [ 8 15]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('customer_churn.csv')\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test,y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test,y_pred)}')\n",
    "print(f'f1: {f1_score(y_test,y_pred)}')\n",
    "print(f'ROC-AUC: {roc_auc_score(y_test,y_pred)}')\n",
    "print(f'Confusion matrix: {confusion_matrix(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78ecfe",
   "metadata": {},
   "source": [
    "3. Disease Stage — Multiclass Logistic Regression\n",
    "Task: Fit multinomial logistic for stage ∈ {0,1,2} using age, b1..b4. Report accuracy, macro-F1, weighted-F1 and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "009c9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25\n",
      "Macro-f1: 0.23164874551971326\n",
      "Weighted-f1: 0.25556182795698923\n",
      "Confusion matrix: [[7 6 3]\n",
      " [3 1 7]\n",
      " [5 6 2]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('disease_stage.csv')\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "model=LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "#average in f1_score --> controls how scores are aggregated across classes\n",
    "#macro --> Equal importance to all classes (just average F1 of each class) and ignores how many samples each class has\n",
    "#weighted --> Multiplies F1 of each class by its number of true samples (support)\n",
    "print(f'Accuracy: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Macro-f1: {f1_score(y_test,y_pred,average=\"macro\")}')   \n",
    "print(f'Weighted-f1: {f1_score(y_test,y_pred,average=\"weighted\")}') \n",
    "print(f'Confusion matrix: {confusion_matrix(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c53c4",
   "metadata": {},
   "source": [
    "4. Flowers — k-NN Classification with CV\n",
    "Task: Fit k-NN on sepal_length, sepal_width, petal_length, petal_width. Use 5-fold CV to choose k ∈ {1,3,…,25}. Report best k, CV score, test accuracy, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00673ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.225\n",
      "Confusion matrix: [[5 6 7]\n",
      " [6 2 4]\n",
      " [3 5 2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "df=pd.read_csv('flowers.csv')\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "#why setting odd values not even for k --> #Odd k reduces ties during majority voting. \n",
    "#If k=4, class0=2 and class1=2 --> tie; if k=3, you will get either 2:1 or 3:0 --> majority\n",
    "k=list(range(1,26,2))\n",
    "cv_score=[]\n",
    "for i in k:\n",
    "  model=KNeighborsClassifier(n_neighbors=i)\n",
    "  score=cross_val_score(model,X_train,y_train,cv=5)   #for each k value, it will get 5 accuracy values (as cv=5) and calculate their average\n",
    "  cv_score.append(score.mean())  #stores the average in cv_scores array\n",
    "\n",
    "#(metric used here is accuracy) higher accuracy --> better model. So we take max of cv_score\n",
    "best_k=k[np.argmax(cv_score)]   #it retreives index of max cv_score value to get best k\n",
    "\n",
    "final_model=KNeighborsClassifier(n_neighbors=best_k)   #creating a k-NN model using best_k\n",
    "final_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=final_model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Confusion matrix: {confusion_matrix(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae76917",
   "metadata": {},
   "source": [
    "5. Airbnb Prices — k-NN Regression with CV\n",
    "Task: Fit k-NN regressor on size_m2, distance_center_km, rating, num_reviews. Use 5-fold CV to pick k ∈ {1,3,…,25} (scaling required). Report CV RMSE, test RMSE, and test R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 143.92254850275012\n",
      "Test RMSE: 113.13890983519951\n",
      "R²: -0.1616135778243346\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "df=pd.read_csv('airbnb.csv')\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "k=list(range(1,26,2))\n",
    "cv_score=[]\n",
    "for i in k:\n",
    "  model=KNeighborsRegressor(n_neighbors=i)\n",
    "  score=cross_val_score(model,X_train,y_train,cv=5,scoring='neg_mean_squared_error')   #it returns negative mse value\n",
    "  cv_score.append(np.sqrt(-score.mean()))   #makes the negative mse value positive\n",
    "\n",
    "#(metric used there is rmse) lower rmse --> better model. So we take min of cv_score\n",
    "best_k=k[np.argmin(cv_score)]\n",
    "\n",
    "final_model=KNeighborsRegressor(n_neighbors=best_k)\n",
    "final_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=final_model.predict(X_test)\n",
    "print(f'CV RMSE: {min(cv_score)}')\n",
    "print(f'Test RMSE: {np.sqrt(mean_squared_error(y_test,y_pred))}')\n",
    "print(f'R²: {r2_score(y_test,y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
